.DEFAULT_GOAL := all
.PHONY : all clean distclean build prep prep_bucket s3copy meta

# One of the gret strengths of using Make for this is that it can avoid re-building code
# when it is not needed. This Makefile takes pains to enumerate the build products and
# avoids building and uploading a new archive if there have been no changes.

# Thanks Stack Overflow http://stackoverflow.com/a/8080530/424301
DIR := $(dir $(lastword $(MAKEFILE_LIST)))
SHELL := /bin/bash

SRC := $(DIR)/src
BUILD := $(DIR)/build
UPSTREAM_BUILD := $(DIR)/../../../naviance-blue-ridge-api
ARCHIVE_DIR := $(DIR)/build/archive
APP_NAME := naviance-blue-ridge-api
ARCHIVE := $(APP_NAME)
# Generated by Jenkinsfile.
TAG_FILE := $(UPSTREAM_BUILD)/TAG
# Credits: https://lists.gnu.org/archive/html/help-make/2009-05/msg00009.html
BUILD_META_DIR := $(abspath $(dir $(ARCHIVE_DIR)/etc))
BUILD_META_FILE := $(BUILD_META_DIR)/meta.txt
ZIP := $(BUILD)/$(ARCHIVE).zip
SKIP_RUN := false
MONITOR_DEPLOYMENT := $(DIR)../../bin/monitor-deployment.sh
GET_BUILD_NUMBER := $(DIR)../../bin/get_build_number.sh
get_s3_file=$(2)-$(shell  $(GET_BUILD_NUMBER) $(1)).zip
AWS_ACCOUNT_ID := $(shell \
	. $(DIR)/../../bin/common.sh >/dev/null 2>&1  && \
	get_aws_account_id)

# Thanks Stack Overflow https://stackoverflow.com/questions/38801796/makefile-set-if-variable-is-empty
ifeq ($(AWS_ACCOUNT_ID),)
     $(error AWS_ACCOUNT_ID not defined)
endif

BUCKET_NAME :=  unmanaged-codedeploy-$(AWS_ACCOUNT_ID)
BUCKET :=  s3://$(BUCKET_NAME)

DEPLOYMENT_APP := tf-blue-ridge-api
DEPLOYMENT_GROUP := qa

# Thanks Stack Overflow http://stackoverflow.com/a/18258352/424301
# This expression has a limitation that it won't work on directories that have spaces
rwildcard=$(foreach d,$(wildcard $1*),$(call rwildcard,$d/,$2) $(filter $(subst *,%,$2),$d))

# Ugh, node_modules has tons of files space in it so the fast rwildcard bit above does not work.
# Fall back to this slower mode.
# Thanks Stack Overflow http://stackoverflow.com/a/21145863/424301
node_modules=$(shell find $(UPSTREAM_BUILD)/node_modules -type f | sed 's/ /\\ /g')
config=$(shell find $(UPSTREAM_BUILD)/config -type f | sed 's/ /\\ /g')

SOURCES := $(call rwildcard, $(SRC), *) \
	       $(call rwildcard, $(UPSTREAM_BUILD)/lib, *) \
	       $(call rwildcard, $(UPSTREAM_BUILD)/public, *) \
	       $(node_modules) \
               $(config)

BUILD_SOURCES=$(UPSTREAM_BUILD)/{lib,node_modules,public,config} $(SRC)/

clean:
	rm -rf $(BUILD)

distclean: clean
	rm -rf $(UPSTREAM_BUILD)/{lib,node_modules,public,config}

prep:
	mkdir -p $(ARCHIVE_DIR)

prep_bucket:
	. $(DIR)/../../env.sh && \
	    . $(DIR)../../bin/common.sh \
			&& ensure_awscli
	. $(DIR)/../../env.sh && \
		aws s3 ls $(BUCKET) >/dev/null \
			|| aws s3 mb $(BUCKET)

build:
	$(DIR)/../../bin/vpn-check.sh
	@echo 'Build is vestigal in this Makefile, nothing to see here.'
	@echo 'The upstream project has a lovely 'run_build.sh' that takes'
	@echo 'care of both building the docker image and doing a docker run.'
	@echo 'Do a "make $(ZIP)" instead'

# Generate meta data to a file so that create-deployments.sh can pick it up
# and send it to NewRelic.
meta:
	$(DIR)/../../bin/vpn-check.sh
	mkdir -p $(BUILD_META_DIR)
	TAG_VAL=$$(cat $(TAG_FILE)) && \
	echo "$(shell $(GET_BUILD_NUMBER)) $(UPSTREAM_BRANCH) $$TAG_VAL" > $(BUILD_META_FILE)

$(ZIP): $(SOURCES)
	$(DIR)/../../bin/vpn-check.sh
	if [ $(SKIP_RUN) = false ]; then \
		cd $(UPSTREAM_BUILD) && ./run-build.sh; \
	fi
	sudo chown $$USER -R $(BUILD_SOURCES)
	rsync -a $(BUILD_SOURCES) $(ARCHIVE_DIR)
	rsync -a \
		$(DIR)../../bin/aws/ \
		$(DIR)../../bin/manage-splunk.sh \
		$(ARCHIVE_DIR)/bin/
	for f in $(ARCHIVE_DIR)/appspec.yml $(ARCHIVE_DIR)/bin/common.sh $(ARCHIVE_DIR)/etc/nodejs.service; do \
		sed -i.bak -e "s/{{ APP_NAME }}/${APP_NAME}/g" $$f; \
		rm -f $$f.bak; \
	done
	cd $(ARCHIVE_DIR) && zip -q -r ../../$(ZIP) *

deploy: prep $(ZIP) s3copy
	. $(DIR)/../../env.sh && \
	S3_FILE=$(call get_s3_file,$(ZIP),$(ARCHIVE)) && \
	deployment=$$(aws deploy create-deployment \
		--application-name $(DEPLOYMENT_APP) \
		--s3-location bucket=$(BUCKET_NAME),key=$(APP_NAME)/$$S3_FILE,bundleType=zip \
		--deployment-group-name $(DEPLOYMENT_GROUP) \
		--output text \
		--region us-east-1) \
		&& $(MONITOR_DEPLOYMENT) $$deployment

# If the Jenkins BUILD_NUMBER env var exists, we use that to build
# an S3_FILE filename variable, else we use the timestamp of the
# archive file in YYYYMMDDTHHMMSS format to build the filename.
# Thanks Stack Overflow http://stackoverflow.com/a/36964153/424301
s3copy: $(ZIP) prep_bucket
 	. $(DIR)/../../env.sh && \
 	S3_FILE=$(call get_s3_file,$(ZIP),$(ARCHIVE)) && \
 	S3_BUILD_META_FILE=$(BUCKET)/$(APP_NAME)/$${S3_FILE}.meta.txt && \
 	aws s3 ls $(BUCKET)/$(APP_NAME)/$$S3_FILE \
 		&& echo "File in S3 is already up to date" \
 		|| (aws s3 cp $(ZIP) $(BUCKET)/$(APP_NAME)/$$S3_FILE --region=us-east-1 && \
 			aws s3 cp $(BUILD_META_FILE) $$S3_BUILD_META_FILE --region=us-east-1)

all: prep $(ZIP) s3copy
